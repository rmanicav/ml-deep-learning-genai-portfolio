{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNdVzgKBxYVNyGIm6nN4iXV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmanicav/Data-science-projects/blob/main/proj14_tiny_llm_prompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment: Code-Focused Inference Your task is to load a pre-trained GPT-2 model and configure it to answer only questions related to Python coding.\n",
        "\n",
        "Load Model and Tokenizer: Load a suitable pre-trained GPT-2 model and its corresponding tokenizer. You can use transformers.AutoModelForCausalLM and transformers.AutoTokenizer. A smaller model like gpt2 or gpt2-medium might be sufficient. Implement a Filtering Mechanism: Use prompt techniques\n",
        "\n",
        "Generate Response: If the prompt is deemed a Python coding question, generate a response using the loaded GPT-2 model. Handle Non-Coding Questions: If the prompt is not related to Python coding, return a predefined message indicating that the model can only answer coding questions.\n",
        "\n",
        "Test: Test your implementation with various prompts, including both Python coding questions and non-coding questions, to ensure the filtering mechanism works correctly."
      ],
      "metadata": {
        "id": "JaAsGzJ17xuX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_Gsi2E5M0-3s"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
        "#Load gpt2-medium\n",
        "model_name = \"gpt2-medium\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to determine if the prompt is related to python, usig few keywords\n",
        "def is_python_question(prompt: str) -> bool:\n",
        "    \"\"\"\n",
        "    Simple keyword-based filter for Python/code questions.\n",
        "    \"\"\"\n",
        "    keywords = [\"python\", \"code\", \"script\", \"function\", \"class\", \"def\", \"import\"]\n",
        "    return any(word in prompt.lower() for word in keywords)\n",
        "#call model generate with model, tokenizer, prompt, and get output\n",
        "def handle_prompt(prompt: str):\n",
        "    if is_python_question(prompt):\n",
        "        # Tokenize with attention mask\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "        # Generate text with attention_mask and pad_token_id set\n",
        "        outputs = model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            max_length=100,\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id  # fixes the warning\n",
        "        )\n",
        "\n",
        "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        print(\"Sample Python code or explanation:\\n\")\n",
        "        print(generated_text)\n",
        "    else:\n",
        "        print(\"Not a Python question\")\n",
        "\n",
        "user_prompt = \"Write a Python function for factorial.\"\n",
        "print(\"User prompt:\", user_prompt)\n",
        "handle_prompt(user_prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbDGK4VA5TCf",
        "outputId": "d453a1ef-7387-4de8-9fc4-e157231ee83b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User prompt: Write a Python function for factorial.\n",
            "Sample Python code or explanation:\n",
            "\n",
            "Write a Python function for factorial.\n",
            "\n",
            "import math def factorial ( n ): \"\"\"Factorial expression. Returns: The nth factorial. \"\"\" return n * factorial ( n - 1 ) # Factorial is a function that returns the nth factorial. def factorial_2 ( n ): \"\"\"Factorial expression. Returns: The 2nd factorial. \"\"\" return factorial_1 ( n - 1 ) # Factorial is a function that returns the 2nd fact\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"Explain german alphabets\"\n",
        "\n",
        "print(\"User prompt:\", user_prompt)\n",
        "handle_prompt(user_prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNAUtsnp6pyY",
        "outputId": "90e4fe30-0968-47ab-b3ee-a1b0caa70455"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User prompt: Explain german alphabets\n",
            "Not a Python question\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#valid example\n",
        "user_prompt = \"Add 2 numbers using python\"\n",
        "\n",
        "print(\"User prompt:\", user_prompt)\n",
        "handle_prompt(user_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws_EVS3660hP",
        "outputId": "45cf090d-c7b4-4ca5-9321-7e94d7cae22c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User prompt: Add 2 numbers using python\n",
            "Sample Python code or explanation:\n",
            "\n",
            "Add 2 numbers using python.\n",
            "\n",
            "import re import math def get_sum(sum=0): sum = 0 for i in range(0, 2): sum += sum * (i + 1) return sum def sum_of_2(sum=0): sum = 0 for i in range(0, 2): sum += sum * (i + 1) return sum def get_sum_of_2(sum=0): sum = 0 for i in range(0\n"
          ]
        }
      ]
    }
  ]
}